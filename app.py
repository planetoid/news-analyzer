import streamlit as st
import requests
from datetime import datetime
import re
import json
from urllib.parse import urlparse, quote
import asyncio
from playwright.async_api import async_playwright
import anthropic

def get_openstreetmap_entity_link(location_name):
    """
    ä½¿ç”¨ OpenStreetMap Nominatim API æŸ¥è©¢åœ°é»ï¼Œä¸¦è¿”å›æ¢ç›®é€£çµ
    å„ªå…ˆæŸ¥æ‰¾ relation é¡å‹çš„æ¢ç›®ï¼ˆé©åˆåœ‹å®¶ã€åŸå¸‚ç­‰è¡Œæ”¿å€åŠƒï¼‰
    
    ç¬¦åˆ Nominatim ä½¿ç”¨æ”¿ç­–ï¼š
    - è¨­ç½®åˆé©çš„ User-Agent è­˜åˆ¥æ‡‰ç”¨ç¨‹å¼
    - é™åˆ¶è«‹æ±‚é »ç‡ï¼ˆç”±ç”¨æˆ¶è§¸ç™¼ï¼Œéæ‰¹é‡è™•ç†ï¼‰
    - é©ç•¶çš„éŒ¯èª¤è™•ç†å’Œå‚™é¸æ–¹æ¡ˆ
    - å°Šé‡ API é™åˆ¶å’Œè¶…æ™‚è¨­å®š
    """
    try:
        # URL encode åœ°é»åç¨±
        encoded_name = quote(location_name)
        
        # ä½¿ç”¨ Nominatim API é€²è¡Œæœå°‹ï¼Œåš´æ ¼éµå¾ªä½¿ç”¨æ”¿ç­–
        search_url = f"https://nominatim.openstreetmap.org/search?q={encoded_name}&format=json&limit=3&addressdetails=1&accept-language=zh"
        
        # è¨­ç½®ç¬¦åˆ Nominatim ä½¿ç”¨æ”¿ç­–çš„ headers
        # æ”¿ç­–è¦æ±‚ï¼šã€ŒProvide a valid HTTP Referer or User-Agent identifying the applicationã€
        headers = {
            'User-Agent': 'NewsAnalyzer/2.1 (Educational news analysis tool; Contact: github.com/planetoid/news-analyzer)',
            'Accept': 'application/json',
            'Accept-Language': 'zh-TW,zh;q=0.9,en;q=0.8',
            'Referer': 'https://github.com/planetoid/news-analyzer'
        }
        
        # ç™¼é€æœå°‹è«‹æ±‚ï¼Œéµå¾ª API ä½¿ç”¨é™åˆ¶
        # æ”¿ç­–è¦æ±‚ï¼šã€ŒNo heavy uses (an absolute maximum of 1 request per second)ã€
        response = requests.get(search_url, headers=headers, timeout=10)
        
        if response.status_code == 200:
            results = response.json()
            
            if not results:
                # æ²’æœ‰æœå°‹çµæœï¼Œè¿”å›æœå°‹é€£çµä½œç‚ºå‚™é¸
                return f"https://www.openstreetmap.org/search?query={encoded_name}"
            
            # å„ªå…ˆæŸ¥æ‰¾ relation é¡å‹çš„çµæœï¼ˆé€šå¸¸æ˜¯è¡Œæ”¿å€åŠƒï¼‰
            for result in results:
                osm_type = result.get('osm_type')
                osm_id = result.get('osm_id')
                place_class = result.get('class', '')
                place_type = result.get('type', '')
                
                # å„ªå…ˆé¸æ“‡ relation é¡å‹çš„è¡Œæ”¿é‚Šç•Œæˆ–åœ°é»
                if (osm_type == 'relation' and 
                    place_class in ['boundary', 'place', 'administrative'] and 
                    osm_id):
                    return f"https://www.openstreetmap.org/relation/{osm_id}"
            
            # å¦‚æœæ²’æœ‰æ‰¾åˆ° relationï¼ŒæŸ¥æ‰¾å…¶ä»–é«˜è³ªé‡çš„çµæœ
            for result in results:
                osm_type = result.get('osm_type')
                osm_id = result.get('osm_id')
                place_class = result.get('class', '')
                
                # é¸æ“‡åœ°é»é¡åˆ¥çš„çµæœ
                if osm_type and osm_id and place_class in ['place', 'boundary']:
                    if osm_type == 'relation':
                        return f"https://www.openstreetmap.org/relation/{osm_id}"
                    elif osm_type == 'way':
                        return f"https://www.openstreetmap.org/way/{osm_id}"
                    elif osm_type == 'node':
                        return f"https://www.openstreetmap.org/node/{osm_id}"
            
            # æœ€å¾Œå˜—è©¦ä»»ä½•æœ‰æ•ˆçš„çµæœ
            first_result = results[0]
            osm_type = first_result.get('osm_type')
            osm_id = first_result.get('osm_id')
            
            if osm_type and osm_id:
                if osm_type == 'relation':
                    return f"https://www.openstreetmap.org/relation/{osm_id}"
                elif osm_type == 'way':
                    return f"https://www.openstreetmap.org/way/{osm_id}"
                elif osm_type == 'node':
                    return f"https://www.openstreetmap.org/node/{osm_id}"
        
        elif response.status_code == 403:
            # API å­˜å–è¢«æ‹’çµ•ï¼Œå¯èƒ½æ˜¯è«‹æ±‚é »ç‡éé«˜æˆ–é•åä½¿ç”¨æ”¿ç­–
            # æ”¿ç­–èªªæ˜ï¼šã€Œmay be classified as faulty and blockedã€
            print(f"Nominatim API 403 éŒ¯èª¤ï¼šå¯èƒ½é•åä½¿ç”¨æ”¿ç­–æˆ–è«‹æ±‚éæ–¼é »ç¹")
            pass
        elif response.status_code == 429:
            # è«‹æ±‚é »ç‡é™åˆ¶
            print(f"Nominatim API 429 éŒ¯èª¤ï¼šè«‹æ±‚é »ç‡è¶…éé™åˆ¶")
            pass
        
        # å¦‚æœ API æŸ¥è©¢å¤±æ•—ï¼Œè¿”å›æœå°‹é€£çµä½œç‚ºå‚™é¸æ–¹æ¡ˆ
        return f"https://www.openstreetmap.org/search?query={encoded_name}"
        
    except requests.exceptions.Timeout:
        # è«‹æ±‚è¶…æ™‚ï¼Œè¿”å›æœå°‹é€£çµä½œç‚ºå‚™é¸
        print(f"Nominatim API è«‹æ±‚è¶…æ™‚")
        pass
    except Exception as e:
        # è¨˜éŒ„éŒ¯èª¤ä½†ä¸é¡¯ç¤ºçµ¦ç”¨æˆ¶ï¼ˆé¿å…å½±éŸ¿ç•Œé¢ï¼‰
        print(f"OpenStreetMap æŸ¥è©¢éŒ¯èª¤: {str(e)}")
    
    # æ‰€æœ‰éŒ¯èª¤æƒ…æ³éƒ½è¿”å›æœå°‹é€£çµä½œç‚ºå‚™é¸æ–¹æ¡ˆ
    encoded_name = quote(location_name)
    return f"https://www.openstreetmap.org/search?query={encoded_name}"

# é é¢é…ç½®
st.set_page_config(
    page_title="ğŸ¥¤ æ–°èæ‰‹æ–é£²åˆ†æå™¨",
    page_icon="ğŸ¥¤",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šç¾©CSSæ¨£å¼
st.markdown("""
<style>
    .main-header {
        text-align: center;
        color: #2E86AB;
        font-size: 2.5rem;
        font-weight: bold;
        margin-bottom: 2rem;
    }
    .drink-card {
        padding: 1.5rem;
        border-radius: 15px;
        margin: 1rem 0;
        text-align: center;
        color: white;
        font-weight: bold;
    }
    .golden-lemon { background: linear-gradient(135deg, #FFD700, #FFA500); }
    .honey-green { background: linear-gradient(135deg, #32CD32, #228B22); }
    .plain-water { background: linear-gradient(135deg, #E0E0E0, #B0B0B0); color: #333; }
    .expired-milk { background: linear-gradient(135deg, #FF6B6B, #CC0000); }
    
    .score-card {
        background: white;
        padding: 1rem;
        border-radius: 10px;
        box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        margin: 0.5rem;
        text-align: left;
    }
    .entity-tag {
        display: inline-block;
        background: #E8F4FD;
        color: #2E86AB;
        padding: 0.3rem 0.8rem;
        margin: 0.2rem;
        border-radius: 20px;
        font-size: 0.9rem;
        text-decoration: none;
    }
    .entity-tag:hover {
        background: #2E86AB;
        color: white;
    }
</style>
""", unsafe_allow_html=True)

class NewsAnalyzer:
    def __init__(self, api_key, model_name="claude-sonnet-4-20250514"):
        self.client = anthropic.Anthropic(api_key=api_key)
        self.model_name = model_name
    
    async def fetch_article_content(self, url):
        """ä½¿ç”¨PlaywrightæŠ“å–ç¶²é å…§å®¹"""
        try:
            async with async_playwright() as p:
                browser = await p.chromium.launch()
                page = await browser.new_page()
                await page.goto(url, wait_until='networkidle')
                
                # å˜—è©¦å¤šç¨®é¸æ“‡å™¨æŠ“å–æ–‡ç« å…§å®¹
                selectors = [
                    'article', '.article-content', '.content', '.post-content',
                    '.entry-content', '#article', '.article-body', 'main'
                ]
                
                content = ""
                for selector in selectors:
                    try:
                        element = await page.query_selector(selector)
                        if element:
                            content = await element.inner_text()
                            if len(content) > 200:  # ç¢ºä¿å…§å®¹è¶³å¤ é•·
                                break
                    except:
                        continue
                
                await browser.close()
                return content if content else "ç„¡æ³•æŠ“å–æ–‡ç« å…§å®¹"
                
        except Exception as e:
            return f"æŠ“å–å¤±æ•—: {str(e)}"
    
    def analyze_news(self, content):
        """ä½¿ç”¨Claude APIåˆ†ææ–°è"""
        prompt = f"""
        è«‹åˆ†æä»¥ä¸‹æ–°èå…§å®¹ï¼Œä¸¦ä»¥JSONæ ¼å¼å›æ‡‰ï¼š

        æ–°èå…§å®¹ï¼š
        {content}

        ã€é‡è¦åˆ†ææŒ‡å—ã€‘
        1. çœŸå¯¦åº¦è©•ä¼°é—œéµæŒ‡æ¨™ï¼š
           - å®˜æ–¹ä¾†æºã€å…·é«”æ•¸æ“šã€æ¬Šå¨äººå£«ç™¼è¨€ â†’ é«˜åˆ† (80-95)
           - ç¶²è·¯å‚³è¨€ã€æœªç¶“è­‰å¯¦æ¶ˆæ¯ â†’ ä½åˆ† (20-40)
           - ã€Œç¶²å‚³ã€ã€ã€Œæ“šèªªã€ã€ã€Œå‚³è¨€ã€é—œéµè© â†’ æ¥µä½åˆ† (10-30)
           - å·²è¢«å®˜æ–¹æ¾„æ¸…/é—¢è¬ å…§å®¹ â†’ æ¥µä½åˆ† (10-25)

        2. é‡è¦æ€§è©•ä¼°æ¨™æº–ï¼š
           - å¨›æ¨‚ã€åœ°æ–¹å°æ´»å‹• â†’ 10-40åˆ†
           - ä¸€èˆ¬ç¤¾æœƒæ–°è â†’ 40-70åˆ†  
           - é‡å¤§æ”¿ç­–ã€ç¶“æ¿Ÿå½±éŸ¿ â†’ 70-100åˆ†

        3. å½±éŸ¿åŠ›è©•ä¼°æ¨™æº–ï¼š
           - å€‹äººè¶£äº‹ã€å°ç¯„åœæ´»å‹• â†’ 5-30åˆ†
           - ç‰¹å®šç¾¤é«”é—œæ³¨äº‹ä»¶ â†’ 30-60åˆ†
           - å»£æ³›ç¤¾æœƒå½±éŸ¿ã€æ”¿ç­–è®Šé© â†’ 60-100åˆ†

        è«‹æä¾›ä»¥ä¸‹åˆ†æï¼š
        {{
            "summary": "100-150å­—çš„é‡é»æ‘˜è¦",
            "target_audience": "é æœŸè®€è€…ç¾¤é«”",
            "truthfulness": çœŸå¯¦åº¦åˆ†æ•¸(0-100),
            "importance": é‡è¦æ€§åˆ†æ•¸(0-100),
            "impact": å½±éŸ¿åŠ›åˆ†æ•¸(0-100),
            "drink_recommendation": {{
                "name": "æ¨è–¦é£²æ–™åç¨±",
                "reason": "æ¨è–¦ç†ç”±",
                "category": "golden_lemon/honey_green/plain_water/expired_milk"
            }},
            "entities": {{
                "people": ["{{"name": "å§“å", "title": "è·ä½", "wiki_link": "ç¶­åŸºç™¾ç§‘é€£çµ"}}"],
                "numbers": ["{{"value": "æ•¸å­—", "context": "èƒŒæ™¯èªªæ˜", "data_link": "ç›¸é—œè³‡æ–™é€£çµ"}}"],
                "locations": ["{{"name": "åœ°é»åç¨±"}}"],
                "organizations": ["{{"name": "æ©Ÿæ§‹åç¨±", "official_link": "å®˜æ–¹é€£çµ"}}"],
                "dates": ["{{"date": "æ—¥æœŸæ™‚é–“", "event": "ç›¸é—œäº‹ä»¶"}}],
                "datasets": ["{{"name": "è³‡æ–™é›†é—œéµå­—", "description": "èªªæ˜", "search_link": "https://data.gov.tw/datasets/search?p=1&size=10&s=è³‡æ–™é›†é—œéµå­—"}}]
            }}
        }}

        ç‰¹åˆ¥æ³¨æ„ï¼š
        - å°æ–¼locationsï¼Œåªéœ€è¦æä¾›åœ°é»åç¨±ï¼Œç³»çµ±æœƒè‡ªå‹•æŸ¥è©¢ OpenStreetMap æ¢ç›®é€£çµ
        - ä¾‹å¦‚ï¼š{{"name": "å°åŒ—å¸‚"}} æˆ– {{"name": "ä¸­æ­£ç´€å¿µå ‚"}}
        - å°æ–¼datasetsï¼Œè«‹æ ¹æ“šæ–°èä¸»é¡Œæå–ç›¸é—œçš„æ”¿åºœè³‡æ–™é›†é—œéµå­—ï¼Œä¸¦è¨­å®šæœå°‹é€£çµ
        - ä¾‹å¦‚ï¼š{{"name": "äº¤é€šäº‹æ•…", "description": "é“è·¯äº¤é€šäº‹æ•…çµ±è¨ˆ", "search_link": "https://data.gov.tw/datasets/search?p=1&size=10&s=äº¤é€šäº‹æ•…"}}

        é£²æ–™åˆ†é¡æ¨™æº–ï¼š
        - golden_lemon (é‡‘æ¡”æª¸æª¬): çœŸå¯¦åº¦>70ä¸”é‡è¦æ€§>70
        - honey_green (èœ‚èœœç¶ èŒ¶): çœŸå¯¦åº¦>70ä½†é‡è¦æ€§â‰¤70
        - plain_water (ç„¡ç³–ç™½é–‹æ°´): çœŸå¯¦åº¦â‰¤70ä¸”é‡è¦æ€§â‰¤70
        - expired_milk (éæœŸå¥¶èŒ¶): çœŸå¯¦åº¦â‰¤70ä½†é‡è¦æ€§>70

        ã€è©•åˆ†ç¯„ä¾‹åƒè€ƒã€‘
        - å¤®è¡Œæ”¿ç­–/é‡å¤§æŠ•è³‡: çœŸå¯¦åº¦85-95, é‡è¦æ€§85-95, å½±éŸ¿åŠ›80-90 â†’ é‡‘æ¡”æª¸æª¬
        - å‹•ç‰©åœ’æ´»å‹•/åœ°æ–¹æ…¶å…¸: çœŸå¯¦åº¦75-85, é‡è¦æ€§25-40, å½±éŸ¿åŠ›15-30 â†’ èœ‚èœœç¶ èŒ¶  
        - ç¶²è·¯å‚³è¨€/å€‹äººç¶“é©—: çœŸå¯¦åº¦10-30, é‡è¦æ€§5-15, å½±éŸ¿åŠ›5-10 â†’ ç„¡ç³–ç™½é–‹æ°´
        - å·²é—¢è¬ å‡è¨Šæ¯: çœŸå¯¦åº¦10-25, é‡è¦æ€§70-90, å½±éŸ¿åŠ›70-90 â†’ éæœŸå¥¶èŒ¶
        """
        
        try:
            response = self.client.messages.create(
                model=self.model_name,
                max_tokens=2000,
                messages=[{"role": "user", "content": prompt}]
            )
            
            # æå–JSONå…§å®¹
            response_text = response.content[0].text
            json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
            if json_match:
                return json.loads(json_match.group())
            else:
                return {"error": "ç„¡æ³•è§£æåˆ†æçµæœ"}
                
        except Exception as e:
            return {"error": f"åˆ†æå¤±æ•—: {str(e)}"}

def display_drink_result(drink_info):
    """é¡¯ç¤ºé£²æ–™æ¨è–¦çµæœ"""
    drink_styles = {
        "golden_lemon": ("ğŸŸ¡ é‡‘æ¡”æª¸æª¬", "golden-lemon"),
        "honey_green": ("ğŸŸ¢ èœ‚èœœç¶ èŒ¶", "honey-green"), 
        "plain_water": ("âšª ç„¡ç³–ç™½é–‹æ°´", "plain-water"),
        "expired_milk": ("ğŸ”´ éæœŸå¥¶èŒ¶", "expired-milk")
    }
    
    drink_name, css_class = drink_styles.get(drink_info["category"], ("â“ æœªçŸ¥é£²æ–™", "plain-water"))
    
    st.markdown(f"""
    <div class="drink-card {css_class}">
        <h2>{drink_name}</h2>
        <h3>{drink_info["name"]}</h3>
        <p>{drink_info["reason"]}</p>
    </div>
    """, unsafe_allow_html=True)

def display_scores(analysis):
    """é¡¯ç¤ºè©•åˆ†å¡ç‰‡"""
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown(f"""
        <div class="score-card">
            <h3>ğŸ¯ çœŸå¯¦åº¦</h3>
            <h2>{analysis['truthfulness']}/100</h2>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown(f"""
        <div class="score-card">
            <h3>â­ é‡è¦æ€§</h3>
            <h2>{analysis['importance']}/100</h2>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        st.markdown(f"""
        <div class="score-card">
            <h3>ğŸ“ˆ å½±éŸ¿åŠ›</h3>
            <h2>{analysis['impact']}/100</h2>
        </div>
        """, unsafe_allow_html=True)

def display_entities(entities):
    """é¡¯ç¤ºå¯¦é«”æå–çµæœ"""
    if entities.get("people"):
        st.subheader("ğŸ‘¥ ç›¸é—œäººç‰©")
        for person in entities["people"]:
            link = person.get("wiki_link", "#")
            st.markdown(f'<a href="{link}" class="entity-tag" target="_blank">{person["name"]} ({person["title"]})</a>', 
                       unsafe_allow_html=True)
    
    if entities.get("numbers"):
        st.subheader("ğŸ”¢ é—œéµæ•¸æ“š")
        for num in entities["numbers"]:
            link = num.get("data_link", "")
            value_context = f'{num["value"]} - {num["context"]}'
            
            # å¦‚æœæœ‰æœ‰æ•ˆé€£çµä¸”ä¸æ˜¯é è¨­çš„ "#"ï¼Œå‰‡ä½¿ç”¨é€£çµ
            if link and link != "#":
                st.markdown(f'<a href="{link}" class="entity-tag" target="_blank">{value_context}</a>', 
                           unsafe_allow_html=True)
            else:
                # æ²’æœ‰é€£çµæ™‚åªé¡¯ç¤ºç´”æ–‡å­—æ¨™ç±¤
                st.markdown(f'<span class="entity-tag">{value_context}</span>', 
                           unsafe_allow_html=True)
    
    if entities.get("locations"):
        st.subheader("ğŸ“ ç›¸é—œåœ°é»")
        for loc in entities["locations"]:
            location_name = loc["name"]
            
            # å‹•æ…‹æŸ¥è©¢ OpenStreetMap æ¢ç›®é€£çµ
            map_link = get_openstreetmap_entity_link(location_name)
            
            # é¡¯ç¤ºå¸¶æœ‰æ¢ç›®é€£çµçš„åœ°é»æ¨™ç±¤
            st.markdown(f'<a href="{map_link}" class="entity-tag" target="_blank">{location_name}</a>', 
                       unsafe_allow_html=True)
    
    if entities.get("organizations"):
        st.subheader("ğŸ¢ ç›¸é—œæ©Ÿæ§‹")
        for org in entities["organizations"]:
            link = org.get("official_link", "#")
            st.markdown(f'<a href="{link}" class="entity-tag" target="_blank">{org["name"]}</a>', 
                       unsafe_allow_html=True)
    
    if entities.get("dates"):
        st.subheader("ğŸ“… é‡è¦æ™‚é–“")
        for date in entities["dates"]:
            st.markdown(f'<span class="entity-tag">{date["date"]} - {date["event"]}</span>', 
                       unsafe_allow_html=True)
    
    if entities.get("datasets"):
        st.subheader("ğŸ“Š ç›¸é—œå…¬é–‹è³‡æ–™é›†")
        for dataset in entities["datasets"]:
            link = dataset.get("data_link", "")
            
            # å¦‚æœæœ‰æœ‰æ•ˆé€£çµä¸”ä¸æ˜¯é è¨­çš„ "#"ï¼Œå‰‡ä½¿ç”¨é€£çµ
            if link and link != "#":
                st.markdown(f'<a href="{link}" class="entity-tag" target="_blank">{dataset["name"]}</a>', 
                           unsafe_allow_html=True)
            else:
                # æ²’æœ‰é€£çµæ™‚åªé¡¯ç¤ºç´”æ–‡å­—æ¨™ç±¤
                st.markdown(f'<span class="entity-tag">{dataset["name"]}</span>', 
                           unsafe_allow_html=True)


def main():
    # ä¸»æ¨™é¡Œ
    st.markdown('<h1 class="main-header">ğŸ¥¤ æ–°èæ‰‹æ–é£²åˆ†æå™¨</h1>', unsafe_allow_html=True)
    
    # å´é‚Šæ¬„ - API Keyè¨­å®š
    with st.sidebar:
        st.header("ğŸ”‘ è¨­å®š")
        api_key = st.text_input("Claude API Key", type="password", 
                               help="è«‹è¼¸å…¥æ‚¨çš„Anthropic APIå¯†é‘°")
        
        model_name = st.text_input("æ¨¡å‹åç¨±", 
                                  value="claude-sonnet-4-20250514",
                                  help="è«‹è¼¸å…¥è¦ä½¿ç”¨çš„Claudeæ¨¡å‹åç¨±\nå¸¸ç”¨é¸é …:\nâ€¢ claude-sonnet-4-20250514\nâ€¢ claude-3-5-sonnet-20241022\nâ€¢ claude-3-opus-20240229")
        
        st.markdown("---")
        st.markdown("""
        ### ğŸ¥¤ é£²æ–™åˆ†é¡ç³»çµ±
        - **ğŸŸ¡ é‡‘æ¡”æª¸æª¬**: å„ªè³ªçœŸå¯¦æ–°è
        - **ğŸŸ¢ èœ‚èœœç¶ èŒ¶**: çœŸå¯¦ä½†ä¸é‡è¦
        - **âšª ç„¡ç³–ç™½é–‹æ°´**: å¹³æ·¡æ™®é€šå…§å®¹
        - **ğŸ”´ éæœŸå¥¶èŒ¶**: å±éšªå‡æ–°è
        """)
    
    if not api_key:
        st.warning("âš ï¸ è«‹åœ¨å´é‚Šæ¬„è¼¸å…¥Claude API Key")
        return
    
    # è¼¸å…¥å€åŸŸ
    tab1, tab2 = st.tabs(["ğŸ”— ç¶²å€è¼¸å…¥", "âœï¸ æ‰‹å‹•è¼¸å…¥"])
    
    with tab1:
        url = st.text_input("ğŸŒ è«‹è¼¸å…¥æ–°èç¶²å€:")
        if st.button("ğŸ“¥ æŠ“å–ä¸¦åˆ†æ", type="primary"):
            if url:
                with st.spinner("æ­£åœ¨æŠ“å–æ–‡ç« å…§å®¹..."):
                    analyzer = NewsAnalyzer(api_key, model_name)
                    
                    # åŸ·è¡Œç•°æ­¥æŠ“å–
                    try:
                        content = asyncio.run(analyzer.fetch_article_content(url))
                        if "ç„¡æ³•æŠ“å–" in content or "æŠ“å–å¤±æ•—" in content:
                            st.error(content)
                            st.info("ğŸ’¡ è«‹å˜—è©¦ä½¿ç”¨ã€Œæ‰‹å‹•è¼¸å…¥ã€åŠŸèƒ½")
                        else:
                            analyze_content(analyzer, content)
                    except Exception as e:
                        st.error(f"æŠ“å–å¤±æ•—: {str(e)}")
            else:
                st.warning("è«‹è¼¸å…¥æœ‰æ•ˆçš„ç¶²å€")
    
    with tab2:
        content = st.text_area("ğŸ“ è«‹è²¼ä¸Šæ–°èå…§å®¹:", height=200)
        if st.button("ğŸ” é–‹å§‹åˆ†æ", type="primary"):
            if content:
                analyzer = NewsAnalyzer(api_key, model_name)
                analyze_content(analyzer, content)
            else:
                st.warning("è«‹è¼¸å…¥æ–°èå…§å®¹")

def analyze_content(analyzer, content):
    """åŸ·è¡Œå…§å®¹åˆ†æä¸¦é¡¯ç¤ºçµæœ"""
    with st.spinner("ğŸ¤– Claudeæ­£åœ¨æ·±åº¦åˆ†æä¸­..."):
        analysis = analyzer.analyze_news(content)
        
        if "error" in analysis:
            st.error(f"âŒ {analysis['error']}")
            return
        
        # é¡¯ç¤ºé£²æ–™æ¨è–¦
        st.markdown("## ğŸ¥¤ æ‚¨çš„æ–°èæ˜¯...")
        display_drink_result(analysis["drink_recommendation"])
        
        # é¡¯ç¤ºè©³ç´°åˆ†æ
        col1, col2 = st.columns([2, 1])
        
        with col1:
            st.markdown("## ğŸ“‹ åˆ†ææ‘˜è¦")
            st.write(analysis["summary"])
            
            st.markdown("## ğŸ‘¥ ç›®æ¨™è®€è€…")
            st.write(analysis["target_audience"])
        
        with col2:
            st.markdown("## ğŸ“Š è©•åˆ†çµæœ")
            display_scores(analysis)
        
        # é¡¯ç¤ºå¯¦é«”ä¿¡æ¯
        if analysis.get("entities"):
            st.markdown("## ğŸ” é—œéµè³‡è¨Šæ“·å–")
            display_entities(analysis["entities"])

# é é¢åº•éƒ¨æ­¸å±¬è²æ˜
st.markdown("---")
st.markdown(
    """
    <div style='text-align: center; color: #666; font-size: 0.8em; margin-top: 2rem;'>
        <p>ğŸ—ºï¸ åœ°ç†è³‡è¨Šç”± <a href="https://www.openstreetmap.org/" target="_blank">OpenStreetMap</a> æä¾› | 
        ä½¿ç”¨ <a href="https://nominatim.openstreetmap.org/" target="_blank">Nominatim</a> åœ°ç†ç·¨ç¢¼æœå‹™ | 
        è³‡æ–™æ¡ç”¨ <a href="https://openstreetmap.org/copyright" target="_blank">ODbL</a> æˆæ¬Š</p>
        <p>ğŸ“ Map data Â© <a href="https://www.openstreetmap.org/copyright" target="_blank">OpenStreetMap contributors</a></p>
    </div>
    """, 
    unsafe_allow_html=True
)

if __name__ == "__main__":
    main()